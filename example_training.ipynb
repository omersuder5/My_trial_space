{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfccbb6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/omerdoruksuder/anaconda3/envs/master-thesis/lib/python3.11/site-packages/exchange_calendars/exchange_calendar.py:2347: FutureWarning: 'T' is deprecated and will be removed in a future version. Please use 'min' instead of 'T'.\n",
      "  align: pd.Timedelta | str = pd.Timedelta(1, \"T\"),\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sigkernel as ksig_pde\n",
    "import sigkernel_ as ksig_disc\n",
    "import utils.data\n",
    "from generators.generators import *\n",
    "from generators.ESN import ESNGenerator\n",
    "from models.ESN_MMD_mvp_trainer import train_ESN_MMD_mvp \n",
    "from sigkernel_.loss import compute_mmd_loss\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "dtype=torch.float64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cb463c",
   "metadata": {},
   "source": [
    "# Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a6ab2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get discretized signature kernel\n",
    "static_kernel_type = 'rq' # type of static kernel to use - rbf, rbfmix, rq, rqmix, rqlinear for\n",
    "n_levels           = 10 # number of levels in the truncated signature kernel\n",
    "disc_sig_kernel_sigma       = 1e-5 # bandwidth parameter for the static kernel\n",
    "\n",
    "kwargs = {\n",
    "    'static_kernel_type': static_kernel_type,\n",
    "    'n_levels': n_levels,\n",
    "    'kernel_sigma': disc_sig_kernel_sigma,\n",
    "}\n",
    "\n",
    "# Define the discretized signature kernel\n",
    "sig_disc_kernel = ksig_disc.kernels.get_discretized_signature_kernel(**kwargs)\n",
    "\n",
    "#---------------------------------\n",
    "# Get pde signature kernel\n",
    "pde_sig_sigma = 1e1 # bandwidth parameter for the static kernel\n",
    "static_kernel = ksig_pde.RBFKernel(sigma=pde_sig_sigma) # define static kernel\n",
    "\n",
    "# Initialize the corresponding signature kernel\n",
    "sig_pde_kernel = ksig_pde.SigKernel(static_kernel, dyadic_order=0)\n",
    "\n",
    "#---------------------------------\n",
    "# Get static kernel\n",
    "static_sigma = 1e3 # bandwidth parameter for the static kernel\n",
    "rbf_kernel = ksig_disc.kernels.RBFKernel(sigma=static_sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbbba66",
   "metadata": {},
   "source": [
    "# Generator, kernel, and training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502bce82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator and ESN details ----------------------\n",
    "T = 200 # length of time series\n",
    "N = 50  # number of samples\n",
    "d = 1   # dimension of time series\n",
    "p = 2   # AR order\n",
    "q = 0   # MA order\n",
    "phi = [0.7, -0.2] # AR coefficients\n",
    "theta = None # MA coefficients\n",
    "\n",
    "h, m, d = 500, 20, 1 # ESN hyperparameters: reservoir size, input dimension, output dimension\n",
    "A = 0.9 * torch.randn(h, h) / (h ** 0.5) # ESN reservoir weight matrix\n",
    "C = torch.randn(h, m) / (m ** 0.5) # ESN input weight matrix\n",
    "\n",
    "# Define data generator and esn\n",
    "x_ar = ARMA(T=T, p=p, q=q, phi=phi, theta=theta)\n",
    "esn = ESNGenerator(A, C, out_dim=d, xi_scale=1.0, eta_scale=0.05)\n",
    "\n",
    "target_generator = x_ar\n",
    "\n",
    "# Kernel details --------------------------------\n",
    "# choose one:\n",
    "# kernel = sig_disc_kernel      # discretized signature kernel\n",
    "kernel = sig_pde_kernel        # pde signature kernel\n",
    "# kernel = rbf_kernel           # static kernel\n",
    "\n",
    "if kernel is rbf_kernel:\n",
    "    kernel_mode = \"static\"\n",
    "else:\n",
    "    kernel_mode = \"sequential\"\n",
    "\n",
    "lead_lag = False\n",
    "lags = 1\n",
    "\n",
    "# Training details ------------------------------\n",
    "epochs=2000\n",
    "batch_size=20\n",
    "lr=1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977af6df",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1e3442",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = train_ESN_MMD_mvp(\n",
    "    esn=esn,\n",
    "    kernel=kernel,\n",
    "    kernel_mode=kernel_mode,      # flatten (B,T,d)->(B,T*d) inside the trainer\n",
    "    T=T,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    lr=lr,\n",
    "    lead_lag=lead_lag,\n",
    "    lags=lags,\n",
    "    target_generator=target_generator,     # <- oracle target, no dataloader\n",
    "    device=device,\n",
    "    dtype=dtype,\n",
    ")\n",
    "\n",
    "print(\"final loss:\", hist[\"losses\"][-1])\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(hist[\"losses\"])\n",
    "plt.title(\"Training Loss History\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master-thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
