{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfccbb6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/omerdoruksuder/anaconda3/envs/master-thesis/lib/python3.11/site-packages/exchange_calendars/exchange_calendar.py:2347: FutureWarning: 'T' is deprecated and will be removed in a future version. Please use 'min' instead of 'T'.\n",
      "  align: pd.Timedelta | str = pd.Timedelta(1, \"T\"),\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sigkernel as ksig_pde\n",
    "import sigkernel_ as ksig_disc\n",
    "import utils.data\n",
    "from generators.generators import *\n",
    "from generators.ESN import ESNGenerator\n",
    "from models.ESN_MMD_mvp_trainer import train_ESN_MMD_mvp \n",
    "from sigkernel_.loss import compute_mmd_loss\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "dtype=torch.float64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cb463c",
   "metadata": {},
   "source": [
    "# Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a6ab2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get discretized signature kernel\n",
    "static_kernel_type = 'rq' # type of static kernel to use - rbf, rbfmix, rq, rqmix, rqlinear for\n",
    "n_levels           = 10 # number of levels in the truncated signature kernel\n",
    "disc_sig_kernel_sigma       = 1e-5 # bandwidth parameter for the static kernel\n",
    "\n",
    "kwargs_disc_sig = {\n",
    "    'static_kernel_type': static_kernel_type,\n",
    "    'n_levels': n_levels,\n",
    "    'kernel_sigma': disc_sig_kernel_sigma,\n",
    "}\n",
    "\n",
    "# Define the discretized signature kernel\n",
    "sig_disc_kernel = ksig_disc.kernels.get_discretized_signature_kernel(**kwargs_disc_sig)\n",
    "\n",
    "#---------------------------------\n",
    "# Get pde signature kernel\n",
    "pde_sig_sigma = 1e1 # bandwidth parameter for the static kernel\n",
    "static_kernel = ksig_pde.RBFKernel(sigma=pde_sig_sigma) # define static kernel\n",
    "\n",
    "# Initialize the corresponding signature kernel\n",
    "sig_pde_kernel = ksig_pde.SigKernel(static_kernel, dyadic_order=0)\n",
    "\n",
    "#---------------------------------\n",
    "# Get static kernel\n",
    "static_sigma = 1e3 # bandwidth parameter for the static kernel\n",
    "rbf_kernel = ksig_disc.kernels.RBFKernel(sigma=static_sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbbba66",
   "metadata": {},
   "source": [
    "# Generator, kernel, and training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "502bce82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator and ESN details ----------------------\n",
    "T = 200 # length of time series\n",
    "N = 50  # number of samples\n",
    "d = 1   # dimension of time series\n",
    "p = 2   # AR order\n",
    "q = 0   # MA order\n",
    "phi = [0.7, -0.2] # AR coefficients\n",
    "theta = None # MA coefficients\n",
    "\n",
    "h, m, d = 500, 20, 1 # ESN hyperparameters: reservoir size, input dimension, output dimension\n",
    "A = 0.9 * torch.randn(h, h) / (h ** 0.5) # ESN reservoir weight matrix\n",
    "C = torch.randn(h, m) / (m ** 0.5) # ESN input weight matrix\n",
    "\n",
    "# Define data generator and esn\n",
    "x_ar = ARMA(T=T, p=p, q=q, phi=phi, theta=theta)\n",
    "esn = ESNGenerator(A, C, out_dim=d, xi_scale=1.0, eta_scale=0.05)\n",
    "\n",
    "target_generator = x_ar\n",
    "\n",
    "# Kernel details --------------------------------\n",
    "# choose one:\n",
    "# kernel = sig_disc_kernel      # discretized signature kernel\n",
    "kernel = sig_pde_kernel        # pde signature kernel\n",
    "# kernel = rbf_kernel           # static kernel\n",
    "\n",
    "if kernel is rbf_kernel:\n",
    "    kernel_mode = \"static\"\n",
    "else:\n",
    "    kernel_mode = \"sequential\"\n",
    "\n",
    "lead_lag = False\n",
    "lags = 1\n",
    "\n",
    "# Training details ------------------------------\n",
    "epochs=2000\n",
    "batch_size=20\n",
    "lr=1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977af6df",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f1e3442",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2000 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m hist \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_ESN_MMD_mvp\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mesn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mesn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkernel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkernel_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkernel_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# flatten (B,T,d)->(B,T*d) inside the trainer\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mT\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlead_lag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlead_lag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_generator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;66;43;03m# <- oracle target, no dataloader\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinal loss:\u001b[39m\u001b[38;5;124m\"\u001b[39m, hist[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlosses\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     17\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/work shared/NTU/RESEARCH/_github_repos/My_trial_space/models/ESN_MMD_mvp_trainer.py:120\u001b[0m, in \u001b[0;36mtrain_ESN_MMD_mvp\u001b[0;34m(esn, kernel, kernel_mode, T, epochs, batch_size, lr, lead_lag, lags, dataloader, target_generator, device, dtype)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m     Xk, Zk \u001b[38;5;241m=\u001b[39m X, Z\n\u001b[0;32m--> 120\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_mmd_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mZk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlead_lag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m opt\u001b[38;5;241m.\u001b[39mzero_grad(set_to_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    123\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/work shared/NTU/RESEARCH/_github_repos/My_trial_space/sigkernel_/loss.py:28\u001b[0m, in \u001b[0;36mcompute_mmd_loss\u001b[0;34m(kernel, X, output, lead_lag, lags)\u001b[0m\n\u001b[1;32m     26\u001b[0m     X \u001b[38;5;241m=\u001b[39m batch_lead_lag_transform(X[:,:,\u001b[38;5;241m1\u001b[39m:], X[:,:,\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m1\u001b[39m], lags) \u001b[38;5;66;03m# inputs are (price series, time dimension, lags to use)\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     output \u001b[38;5;241m=\u001b[39m batch_lead_lag_transform(output[:,:,\u001b[38;5;241m1\u001b[39m:], output[:,:,\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m1\u001b[39m], lags)\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmmd_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/work shared/NTU/RESEARCH/_github_repos/My_trial_space/sigkernel_/loss.py:11\u001b[0m, in \u001b[0;36mmmd_loss\u001b[0;34m(X, Y, kernel)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(kernel, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompute_Gram\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (Y\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m X\u001b[38;5;241m.\u001b[39mrequires_grad):\n\u001b[1;32m      9\u001b[0m     X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mrequires_grad_(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 11\u001b[0m Kxx \u001b[38;5;241m=\u001b[39m \u001b[43mgram\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m Kyy \u001b[38;5;241m=\u001b[39m gram(kernel, Y, Y)\n\u001b[1;32m     13\u001b[0m Kxy \u001b[38;5;241m=\u001b[39m gram(kernel, X, Y)\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/work shared/NTU/RESEARCH/_github_repos/My_trial_space/sigkernel_/kernels.py:153\u001b[0m, in \u001b[0;36mgram\u001b[0;34m(kernel, X, Y)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;124;03mReturns Gram matrix K(X,Y) for either:\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;124;03m  - callable kernel: kernel(X,Y)\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;124;03m  - object with compute_Gram: kernel.compute_Gram(X,Y)\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(kernel, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompute_Gram\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 153\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mkernel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_Gram\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(kernel, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompute_gram\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m kernel\u001b[38;5;241m.\u001b[39mcompute_gram(X, Y)\n",
      "File \u001b[0;32m~/anaconda3/envs/master-thesis/lib/python3.11/site-packages/sigkernel/sigkernel.py:102\u001b[0m, in \u001b[0;36mSigKernel.compute_Gram\u001b[0;34m(self, X, Y, sym, max_batch)\u001b[0m\n\u001b[1;32m    100\u001b[0m batch_Y \u001b[38;5;241m=\u001b[39m Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_X \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m max_batch \u001b[38;5;129;01mand\u001b[39;00m batch_Y \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m max_batch:\n\u001b[0;32m--> 102\u001b[0m     K \u001b[38;5;241m=\u001b[39m \u001b[43m_SigKernelGram\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatic_kernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdyadic_order\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msym\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_naive_solver\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m batch_X \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m max_batch \u001b[38;5;129;01mand\u001b[39;00m batch_Y \u001b[38;5;241m>\u001b[39m max_batch:\n\u001b[1;32m    104\u001b[0m     cutoff \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(batch_Y\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/master-thesis/lib/python3.11/site-packages/torch/autograd/function.py:553\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    552\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    555\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[1;32m    556\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    557\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    558\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    559\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    560\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    561\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/master-thesis/lib/python3.11/site-packages/sigkernel/sigkernel.py:382\u001b[0m, in \u001b[0;36m_SigKernelGram.forward\u001b[0;34m(ctx, X, Y, static_kernel, dyadic_order, sym, _naive_solver)\u001b[0m\n\u001b[1;32m    379\u001b[0m     G \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(sigkernel_Gram_cython(G_static_\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy(), sym, _naive_solver), dtype\u001b[38;5;241m=\u001b[39mG_static\u001b[38;5;241m.\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mG_static\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mrequires_grad:\n\u001b[0;32m--> 382\u001b[0m     grad_points \u001b[38;5;241m=\u001b[39m \u001b[43mprep_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mG_static\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msym\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatic_kernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdyadic_order\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_naive_solver\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    383\u001b[0m     ctx\u001b[38;5;241m.\u001b[39msave_for_backward(X, Y, grad_points)\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m G[:, :, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/master-thesis/lib/python3.11/site-packages/sigkernel/sigkernel.py:466\u001b[0m, in \u001b[0;36mprep_backward\u001b[0;34m(X, Y, G, G_static, sym, static_kernel, dyadic_order, _naive_solver)\u001b[0m\n\u001b[1;32m    464\u001b[0m Diff_2 \u001b[38;5;241m=\u001b[39m G_h[:,:,\u001b[38;5;241m1\u001b[39m:,\u001b[38;5;241m1\u001b[39m:,:] \u001b[38;5;241m-\u001b[39m G_h[:,:,\u001b[38;5;241m1\u001b[39m:,:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,:] \u001b[38;5;241m-\u001b[39m (G_static[:,:,\u001b[38;5;241m1\u001b[39m:,\u001b[38;5;241m1\u001b[39m:])[:,:,:,:,\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m+\u001b[39m (G_static[:,:,\u001b[38;5;241m1\u001b[39m:,:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])[:,:,:,:,\u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m    465\u001b[0m Diff_2 \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m G_h[:,:,:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m:,:] \u001b[38;5;241m+\u001b[39m G_h[:,:,:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,:] \u001b[38;5;241m+\u001b[39m (G_static[:,:,:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m:])[:,:,:,:,\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m-\u001b[39m (G_static[:,:,:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])[:,:,:,:,\u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[0;32m--> 466\u001b[0m Diff_2 \u001b[38;5;241m=\u001b[39m tile(\u001b[43mtile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDiff_2\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdyadic_order\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdyadic_order),\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdyadic_order)\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdyadic_order)\n\u001b[1;32m    468\u001b[0m grad_1 \u001b[38;5;241m=\u001b[39m (GG[:,:,:,:,\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m Diff_1)\u001b[38;5;241m/\u001b[39mh     \u001b[38;5;66;03m# shape (A,B,MM,NN,D)\u001b[39;00m\n\u001b[1;32m    469\u001b[0m grad_2 \u001b[38;5;241m=\u001b[39m (GG[:,:,:,:,\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m Diff_2)\u001b[38;5;241m/\u001b[39mh\n",
      "File \u001b[0;32m~/anaconda3/envs/master-thesis/lib/python3.11/site-packages/sigkernel/sigkernel.py:574\u001b[0m, in \u001b[0;36mtile\u001b[0;34m(a, dim, n_tile)\u001b[0m\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39mview(xsize)\n\u001b[1;32m    573\u001b[0m \u001b[38;5;66;03m# ===========================================================================================================\u001b[39;00m\n\u001b[0;32m--> 574\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtile\u001b[39m(a, dim, n_tile):\n\u001b[1;32m    575\u001b[0m     init_dim \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39msize(dim)\n\u001b[1;32m    576\u001b[0m     repeat_idx \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m a\u001b[38;5;241m.\u001b[39mdim()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hist = train_ESN_MMD_mvp(\n",
    "    esn=esn,\n",
    "    kernel=kernel,\n",
    "    kernel_mode=kernel_mode,      # flatten (B,T,d)->(B,T*d) inside the trainer\n",
    "    T=T,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    lr=lr,\n",
    "    lead_lag=lead_lag,\n",
    "    lags=lags,\n",
    "    target_generator=target_generator,     # <- oracle target, no dataloader\n",
    "    device=device,\n",
    "    dtype=dtype,\n",
    ")\n",
    "\n",
    "print(\"final loss:\", hist[\"losses\"][-1])\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(hist[\"losses\"])\n",
    "plt.title(\"Training Loss History\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master-thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
